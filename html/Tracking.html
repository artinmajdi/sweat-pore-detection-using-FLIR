
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Tracking</title><meta name="generator" content="MATLAB 9.7"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2020-03-13"><meta name="DC.source" content="Tracking.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#1">Sweat Pore Detection</a></li><li><a href="#3">Create System Objects</a></li><li><a href="#4">Initialize Tracks</a></li><li><a href="#5">Read a Video Frame</a></li><li><a href="#6">Predict New Locations of Existing Tracks</a></li><li><a href="#7">Assign Detections to Tracks</a></li><li><a href="#8">Update Assigned Tracks</a></li><li><a href="#9">Update Unassigned Tracks</a></li><li><a href="#10">Delete Lost Tracks</a></li><li><a href="#11">Create New Tracks</a></li><li><a href="#12">Display Tracking Results</a></li><li><a href="#13">Summary</a></li></ul></div><h2 id="1">Sweat Pore Detection</h2><p>The association of detections to the same object is based solely on motion. The motion of each track is estimated by a Kalman filter. The filter is used to predict the track's location in each frame, and determine the likelihood of each detection being assigned to each track.</p><p>Track maintenance becomes an important aspect of this example. In any given frame, some detections may be assigned to tracks, while other detections and tracks may remain unassigned. The assigned tracks are updated using the corresponding detections. The unassigned tracks are marked invisible. An unassigned detection begins a new track.</p><p>Each track keeps count of the number of consecutive frames, where it remained unassigned. If the count exceeds a specified threshold, the example assumes that the object left the field of view and it deletes the track.</p><pre class="codeinput"><span class="keyword">function</span> Tracking()  <span class="comment">% modified MotionBasedMultiObjectTracking</span>
</pre><pre class="codeinput">    UserInfo = init_directories(<span class="string">'windows_data7'</span>);

    filename = [UserInfo.Directories.address , UserInfo.Directories.TIF_video];
    info = imfinfo(filename);
    L = length(info);

    obj = setupSystemObjects(); <span class="comment">% Create System objects used for reading video, detecting moving objects, and displaying the results.</span>

    tracks = initializeTracks(); <span class="comment">% Create an empty array of tracks.</span>
    nextId = 1; <span class="comment">% ID of the next track</span>


    <span class="comment">% while ~isDone(obj.reader)   % Detect moving objects, and track them across video frames.</span>
    <span class="keyword">for</span> index = 1:L
        disp([<span class="string">'index'</span>,string(index)])
        frame = reading_frame(index, UserInfo.inputMode);
<span class="comment">%         [mask, frame_enhanced] = segmentation(frame);</span>
        frame_enhanced = enhancement_filter(frame, <span class="string">"same"</span>);
        mask = segmentation(frame_enhanced, Background);

        Results = detecting_objects(mask);
        bboxes = Results.bboxes;
        centroids = Results.centroids;

        predictNewLocationsOfTracks();
        [assignments, unassignedTracks, unassignedDetections] = detectionToTrackAssignment();

        updateAssignedTracks();
        updateUnassignedTracks();
        deleteLostTracks();
        createNewTracks();
        displayTrackingResults();
    <span class="keyword">end</span>


    <span class="keyword">function</span> UserInfo = init_directories(OS)

        <span class="keyword">if</span> strcmp(OS,<span class="string">'linux_data7'</span>)
            input_Hard_Drive = <span class="string">'\media\artin\HDD1\'</span>;
        <span class="keyword">elseif</span> strcmp(OS,<span class="string">'windows_data7'</span>)
            input_Hard_Drive = <span class="string">'H:\Datasets\'</span>;
        <span class="keyword">end</span>

        UserInfo.Directories.address   = [input_Hard_Drive, <span class="string">'FLIR Datasets\Dataset\new_Jan2\'</span>];
        UserInfo.Directories.video     = <span class="string">'Rec-000020 - Copy - test.wmv'</span>;
        UserInfo.Directories.TIF_video = <span class="string">'Rec-000020 - Copy - test.tif'</span>;
        UserInfo.inputMode = <span class="string">'reading_tif_video'</span>;

        <span class="keyword">if</span> contains(OS,<span class="string">'linux'</span>)
             UserInfo.Directories.address = strrep(UserInfo.Directories.address,<span class="string">'\'</span>,<span class="string">'/'</span>);
        <span class="keyword">end</span>

        UserInfo.invisibleForTooLong = 20;
        UserInfo.ageThreshold = 8;

        <span class="comment">% Kalman Filter Parameters</span>
        UserInfo.costOfNonAssignment = 20;
        UserInfo.MotionModel = <span class="string">'ConstantVelocity'</span>;
        UserInfo.InitialEstimateError = [200, 50];
        UserInfo.MotionNoise = [100, 25];
        UserInfo.MeasurementNoise = 100;

        UserInfo.minVisibleCount = 8;

        Pore_Size = inputdlg({<span class="string">'Minimum'</span>,<span class="string">'Maximum'</span>},<span class="string">'Insert Pore Size'</span>,[1,40],{<span class="string">'1'</span>,<span class="string">'15'</span>});
        UserInfo.pore_size_range = [str2double(Pore_Size{1}) , str2double(Pore_Size{2}) ];
    <span class="keyword">end</span>

    mask = segmentating_sweat_pores(frame);


    <span class="keyword">function</span> im = reading_frame(index, mode)

        <span class="keyword">if</span> strcmp(mode , <span class="string">'read_from_individual_frames'</span>)
            name = [<span class="string">'Rec-000020 - Copy - test_'</span>,int2str(index),<span class="string">'.tif'</span>];
            Dirr = [Directories.address, name];
            im = imread(Dirr);
        <span class="keyword">else</span>
            im = imread(filename, index);
        <span class="keyword">end</span>

        im = func_normalize(im,1);

        <span class="keyword">function</span> im = func_normalize(im,type)
            im = single(im);
            mn = min(im(:));
            mx = max(im(:));
            <span class="keyword">if</span> type == 16
                im = uint16(  (im-mn)*(2^16)/(mx-mn)  );
            <span class="keyword">elseif</span> type == 8
                im = uint8(  (im-mn)*(2^8)/(mx-mn)  );
            <span class="keyword">elseif</span> type == 1
                im = (im-mn)/(mx-mn);
            <span class="keyword">end</span>
        <span class="keyword">end</span>

    <span class="keyword">end</span>
</pre><pre class="codeoutput error">Error using imfinfo (line 142)
Unable to open file "H:\Datasets\FLIR Datasets\Dataset\new_Jan2\Rec-000020 - Copy - test.tif" for reading.

Error in Tracking (line 25)
    info = imfinfo(filename);
</pre><h2 id="3">Create System Objects</h2><p>Create System objects used for reading the video frames, detecting foreground objects, and displaying results.</p><pre class="codeinput">    <span class="keyword">function</span> obj = setupSystemObjects()
        <span class="comment">% Initialize Video I/O</span>
        <span class="comment">% Create objects for reading a video from a file, drawing the tracked</span>
        <span class="comment">% objects in each frame, and playing the video.</span>

        <span class="comment">% Create a video file reader.</span>
        <span class="comment">%         obj.reader = vision.VideoFileReader('atrium.mp4');</span>
        obj.reader = vision.VideoFileReader([UserInfo.Directories.address , UserInfo.Directories.video]); <span class="comment">% 'G:\FLIR Datasets\Dataset\new_Jan2\Rec-000020 - Copy - test.wmv');</span>

        <span class="comment">% Create two video players, one to display the video,</span>
        <span class="comment">% and one to display the foreground mask.</span>
        obj.maskPlayer = vision.VideoPlayer(<span class="string">'Position'</span>, [740, 400, 700, 400]);
        obj.videoPlayer = vision.VideoPlayer(<span class="string">'Position'</span>, [20, 400, 700, 400]);

        <span class="comment">% Create System objects for foreground detection and blob analysis</span>

        <span class="comment">% The foreground detector is used to segment moving objects from</span>
        <span class="comment">% the background. It outputs a binary mask, where the pixel value</span>
        <span class="comment">% of 1 corresponds to the foreground and the value of 0 corresponds</span>
        <span class="comment">% to the background.</span>

        obj.detector = vision.ForegroundDetector(<span class="string">'NumGaussians'</span>, 3, <span class="keyword">...</span>
            <span class="string">'NumTrainingFrames'</span>, 40, <span class="string">'MinimumBackgroundRatio'</span>, 0.7);

        <span class="comment">% Connected groups of foreground pixels are likely to correspond to moving</span>
        <span class="comment">% objects.  The blob analysis System object is used to find such groups</span>
        <span class="comment">% (called 'blobs' or 'connected components'), and compute their</span>
        <span class="comment">% characteristics, such as area, centroid, and the bounding box.</span>

        obj.blobAnalyser = vision.BlobAnalysis(<span class="string">'BoundingBoxOutputPort'</span>, true, <span class="keyword">...</span>
            <span class="string">'AreaOutputPort'</span>, true, <span class="string">'CentroidOutputPort'</span>, true, <span class="keyword">...</span>
            <span class="string">'MinimumBlobArea'</span>, 400);
    <span class="keyword">end</span>
</pre><h2 id="4">Initialize Tracks</h2><p>The <tt>initializeTracks</tt> function creates an array of tracks, where each track is a structure representing a moving object in the video. The purpose of the structure is to maintain the state of a tracked object. The state consists of information used for detection to track assignment, track termination, and display.</p><p>The structure contains the following fields:</p><div><ul><li><tt>id</tt> :                  the integer ID of the track</li><li><tt>bbox</tt> :                the current bounding box of the object; used                           for display</li><li><tt>kalmanFilter</tt> :        a Kalman filter object used for motion-based                           tracking</li><li><tt>age</tt> :                 the number of frames since the track was first                           detected</li><li><tt>totalVisibleCount</tt> :   the total number of frames in which the track                           was detected (visible)</li><li><tt>consecutiveInvisibleCount</tt> : the number of consecutive frames for                                  which the track was not detected (invisible).</li></ul></div><p>Noisy detections tend to result in short-lived tracks. For this reason, the example only displays an object after it was tracked for some number of frames. This happens when <tt>totalVisibleCount</tt> exceeds a specified threshold.</p><p>When no detections are associated with a track for several consecutive frames, the example assumes that the object has left the field of view and deletes the track. This happens when <tt>consecutiveInvisibleCount</tt> exceeds a specified threshold. A track may also get deleted as noise if it was tracked for a short time, and marked invisible for most of the frames.</p><pre class="codeinput">    <span class="keyword">function</span> tracks = initializeTracks()
        <span class="comment">% create an empty array of tracks</span>
        tracks = struct(<span class="keyword">...</span>
            <span class="string">'id'</span>, {}, <span class="keyword">...</span>
            <span class="string">'bbox'</span>, {}, <span class="keyword">...</span>
            <span class="string">'kalmanFilter'</span>, {}, <span class="keyword">...</span>
            <span class="string">'age'</span>, {}, <span class="keyword">...</span>
            <span class="string">'totalVisibleCount'</span>, {}, <span class="keyword">...</span>
            <span class="string">'consecutiveInvisibleCount'</span>, {});
    <span class="keyword">end</span>
</pre><h2 id="5">Read a Video Frame</h2><p>Read the next video frame from the video file.</p><pre class="codeinput">    <span class="keyword">function</span> frame = readFrame()
        frame = obj.reader.step();
    <span class="keyword">end</span>
</pre><h2 id="6">Predict New Locations of Existing Tracks</h2><p>Use the Kalman filter to predict the centroid of each track in the current frame, and update its bounding box accordingly.</p><pre class="codeinput">    <span class="keyword">function</span> predictNewLocationsOfTracks()
        <span class="keyword">for</span> i = 1:length(tracks)
            bbox = tracks(i).bbox;

            <span class="comment">% Predict the current location of the track.</span>
            predictedCentroid = predict(tracks(i).kalmanFilter);

            <span class="comment">% Shift the bounding box so that its center is at</span>
            <span class="comment">% the predicted location.</span>
            predictedCentroid = int32(predictedCentroid) - bbox(3:4) / 2;
            tracks(i).bbox = [predictedCentroid, bbox(3:4)];
        <span class="keyword">end</span>
    <span class="keyword">end</span>
</pre><h2 id="7">Assign Detections to Tracks</h2><p>Assigning object detections in the current frame to existing tracks is done by minimizing cost. The cost is defined as the negative log-likelihood of a detection corresponding to a track.</p><p>The algorithm involves two steps:</p><p>Step 1: Compute the cost of assigning every detection to each track using the <tt>distance</tt> method of the <tt>vision.KalmanFilter</tt> System object&#8482;. The cost takes into account the Euclidean distance between the predicted centroid of the track and the centroid of the detection. It also includes the confidence of the prediction, which is maintained by the Kalman filter. The results are stored in an MxN matrix, where M is the number of tracks, and N is the number of detections.</p><p>Step 2: Solve the assignment problem represented by the cost matrix using the <tt>assignDetectionsToTracks</tt> function. The function takes the cost matrix and the cost of not assigning any detections to a track.</p><p>The value for the cost of not assigning a detection to a track depends on the range of values returned by the <tt>distance</tt> method of the <tt>vision.KalmanFilter</tt>. This value must be tuned experimentally. Setting it too low increases the likelihood of creating a new track, and may result in track fragmentation. Setting it too high may result in a single track corresponding to a series of separate moving objects.</p><p>The <tt>assignDetectionsToTracks</tt> function uses the Munkres' version of the Hungarian algorithm to compute an assignment which minimizes the total cost. It returns an M x 2 matrix containing the corresponding indices of assigned tracks and detections in its two columns. It also returns the indices of tracks and detections that remained unassigned.</p><pre class="codeinput">    <span class="keyword">function</span> [assignments, unassignedTracks, unassignedDetections] = detectionToTrackAssignment()

        nTracks = length(tracks);
        nDetections = size(centroids, 1);

        <span class="comment">% Compute the cost of assigning each detection to each track.</span>
        cost = zeros(nTracks, nDetections);
        <span class="keyword">for</span> i = 1:nTracks
            cost(i, :) = distance(tracks(i).kalmanFilter, centroids);
        <span class="keyword">end</span>

        <span class="comment">% Solve the assignment problem.</span>
        costOfNonAssignment = UserInfo.costOfNonAssignment; <span class="comment">%  20;</span>
        [assignments, unassignedTracks, unassignedDetections] = <span class="keyword">...</span>
            assignDetectionsToTracks(cost, costOfNonAssignment);
    <span class="keyword">end</span>
</pre><h2 id="8">Update Assigned Tracks</h2><p>The <tt>updateAssignedTracks</tt> function updates each assigned track with the corresponding detection. It calls the <tt>correct</tt> method of <tt>vision.KalmanFilter</tt> to correct the location estimate. Next, it stores the new bounding box, and increases the age of the track and the total visible count by 1. Finally, the function sets the invisible count to 0.</p><pre class="codeinput">    <span class="keyword">function</span> updateAssignedTracks()
        numAssignedTracks = size(assignments, 1);
        <span class="keyword">for</span> i = 1:numAssignedTracks
            trackIdx = assignments(i, 1);
            detectionIdx = assignments(i, 2);
            centroid = centroids(detectionIdx, :);
            bbox = bboxes(detectionIdx, :);

            <span class="comment">% Correct the estimate of the object's location</span>
            <span class="comment">% using the new detection.</span>
            correct(tracks(trackIdx).kalmanFilter, centroid);

            <span class="comment">% Replace predicted bounding box with detected</span>
            <span class="comment">% bounding box.</span>
            tracks(trackIdx).bbox = bbox;

            <span class="comment">% Update track's age.</span>
            tracks(trackIdx).age = tracks(trackIdx).age + 1;

            <span class="comment">% Update visibility.</span>
            tracks(trackIdx).totalVisibleCount = <span class="keyword">...</span>
                tracks(trackIdx).totalVisibleCount + 1;
            tracks(trackIdx).consecutiveInvisibleCount = 0;
        <span class="keyword">end</span>
    <span class="keyword">end</span>
</pre><h2 id="9">Update Unassigned Tracks</h2><p>Mark each unassigned track as invisible, and increase its age by 1.</p><pre class="codeinput">    <span class="keyword">function</span> updateUnassignedTracks()
        <span class="keyword">for</span> i = 1:length(unassignedTracks)
            ind = unassignedTracks(i);
            tracks(ind).age = tracks(ind).age + 1;
            tracks(ind).consecutiveInvisibleCount = <span class="keyword">...</span>
                tracks(ind).consecutiveInvisibleCount + 1;
        <span class="keyword">end</span>
    <span class="keyword">end</span>
</pre><h2 id="10">Delete Lost Tracks</h2><p>The <tt>deleteLostTracks</tt> function deletes tracks that have been invisible for too many consecutive frames. It also deletes recently created tracks that have been invisible for too many frames overall.</p><pre class="codeinput">    <span class="keyword">function</span> deleteLostTracks()
        <span class="keyword">if</span> isempty(tracks)
            <span class="keyword">return</span>;
        <span class="keyword">end</span>

        invisibleForTooLong = UserInfo.invisibleForTooLong; <span class="comment">% 20;</span>
        ageThreshold = UserInfo.ageThreshold; <span class="comment">%  8;</span>

        <span class="comment">% Compute the fraction of the track's age for which it was visible.</span>
        ages = [tracks(:).age];
        totalVisibleCounts = [tracks(:).totalVisibleCount];
        visibility = totalVisibleCounts ./ ages;

        <span class="comment">% Find the indices of 'lost' tracks.</span>
        lostInds = (ages &lt; ageThreshold &amp; visibility &lt; 0.6) | <span class="keyword">...</span>
            [tracks(:).consecutiveInvisibleCount] &gt;= invisibleForTooLong;

        <span class="comment">% Delete lost tracks.</span>
        tracks = tracks(~lostInds);
    <span class="keyword">end</span>
</pre><h2 id="11">Create New Tracks</h2><p>Create new tracks from unassigned detections. Assume that any unassigned detection is a start of a new track. In practice, you can use other cues to eliminate noisy detections, such as size, location, or appearance.</p><pre class="codeinput">    <span class="keyword">function</span> createNewTracks()
        centroids = centroids(unassignedDetections, :);
        bboxes = bboxes(unassignedDetections, :);

        <span class="keyword">for</span> i = 1:size(centroids, 1)

            centroid = centroids(i,:);
            bbox = bboxes(i, :);

            <span class="comment">% Create a Kalman filter object.</span>
            kalmanFilter = configureKalmanFilter(UserInfo.MotionModel, centroid, UserInfo.InitialEstimateError, UserInfo.MotionNoise, UserInfo.MeasurementNoise);


            <span class="comment">% Create a new track.</span>
            newTrack = struct(<span class="keyword">...</span>
                <span class="string">'id'</span>, nextId, <span class="keyword">...</span>
                <span class="string">'bbox'</span>, bbox, <span class="keyword">...</span>
                <span class="string">'kalmanFilter'</span>, kalmanFilter, <span class="keyword">...</span>
                <span class="string">'age'</span>, 1, <span class="keyword">...</span>
                <span class="string">'totalVisibleCount'</span>, 1, <span class="keyword">...</span>
                <span class="string">'consecutiveInvisibleCount'</span>, 0);

            <span class="comment">% Add it to the array of tracks.</span>
            tracks(end + 1) = newTrack;

            <span class="comment">% Increment the next id.</span>
            nextId = nextId + 1;
        <span class="keyword">end</span>
    <span class="keyword">end</span>
</pre><h2 id="12">Display Tracking Results</h2><p>The <tt>displayTrackingResults</tt> function draws a bounding box and label ID for each track on the video frame and the foreground mask. It then displays the frame and the mask in their respective video players.</p><pre class="codeinput">    <span class="keyword">function</span> displayTrackingResults()
        <span class="comment">% Convert the frame and the mask to uint8 RGB.</span>
        frame = uint8(repmat(frame, [1, 1, 3]) .* 255); <span class="comment">%im2uint8(frame);</span>
        mask = uint8(repmat(mask, [1, 1, 3])) .* 255;

        minVisibleCount = UserInfo.minVisibleCount; <span class="comment">%8;</span>
        <span class="keyword">if</span> ~isempty(tracks)

            <span class="comment">% Noisy detections tend to result in short-lived tracks.</span>
            <span class="comment">% Only display tracks that have been visible for more than</span>
            <span class="comment">% a minimum number of frames.</span>
            reliableTrackInds = [tracks(:).totalVisibleCount] &gt; minVisibleCount;
            reliableTracks = tracks(reliableTrackInds);

            <span class="comment">% Display the objects. If an object has not been detected</span>
            <span class="comment">% in this frame, display its predicted bounding box.</span>
            <span class="keyword">if</span> ~isempty(reliableTracks)
                <span class="comment">% Get bounding boxes.</span>
                pore_ID = cat(1,tracks.id);
                Time_Pore_Stayed_Active = cat(1,tracks.totalVisibleCount);
                When_Pore_Appeared = cat(1,tracks.age);
                T = table(pore_ID, Time_Pore_Stayed_Active, When_Pore_Appeared);
                bboxes = cat(1, reliableTracks.bbox);

                <span class="comment">% Get ids.</span>
                ids = int32([reliableTracks(:).id]);

                <span class="comment">% Create labels for objects indicating the ones for</span>
                <span class="comment">% which we display the predicted rather than the actual</span>
                <span class="comment">% location.</span>
                labels = cellstr(int2str(ids'));
                predictedTrackInds = <span class="keyword">...</span>
                    [reliableTracks(:).consecutiveInvisibleCount] &gt; 0;
                isPredicted = cell(size(labels));
                isPredicted(predictedTrackInds) = {<span class="string">' predicted'</span>};
                labels = strcat(labels, isPredicted);

                <span class="comment">% Draw the objects on the frame.</span>
                frame = insertObjectAnnotation(frame, <span class="string">'rectangle'</span>, <span class="keyword">...</span>
                    bboxes, labels);

                <span class="comment">% Draw the objects on the mask.</span>
<span class="comment">%                 mask = insertObjectAnnotation(mask, 'rectangle', ...</span>
<span class="comment">%                     bboxes, labels);</span>
            <span class="keyword">end</span>
        <span class="keyword">end</span>

        <span class="comment">% Display the mask and the frame.</span>
        obj.maskPlayer.step(mask);
        obj.videoPlayer.step(frame);
    <span class="keyword">end</span>
</pre><h2 id="13">Summary</h2><p>This example created a motion-based system for detecting and tracking multiple moving objects. Try using a different video to see if you are able to detect and track objects. Try modifying the parameters for the detection, assignment, and deletion steps.</p><p>The tracking in this example was solely based on motion with the assumption that all objects move in a straight line with constant speed. When the motion of an object significantly deviates from this model, the example may produce tracking errors. Notice the mistake in tracking the person labeled #12, when he is occluded by the tree.</p><p>The likelihood of tracking errors can be reduced by using a more complex motion model, such as constant acceleration, or by using multiple Kalman filters for every object. Also, you can incorporate other cues for associating detections over time, such as size, shape, and color.</p><pre class="codeinput"><span class="keyword">end</span>
</pre><p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2019b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Sweat Pore Detection
% The association of detections to the same object is based solely on
% motion. The motion of each track is estimated by a Kalman filter. The
% filter is used to predict the track's location in each frame, and
% determine the likelihood of each detection being assigned to each
% track.
%
% Track maintenance becomes an important aspect of this example. In any
% given frame, some detections may be assigned to tracks, while other
% detections and tracks may remain unassigned. The assigned tracks are
% updated using the corresponding detections. The unassigned tracks are
% marked invisible. An unassigned detection begins a new track.
%
% Each track keeps count of the number of consecutive frames, where it
% remained unassigned. If the count exceeds a specified threshold, the
% example assumes that the object left the field of view and it deletes the
% track.


function Tracking()  % modified MotionBasedMultiObjectTracking

    UserInfo = init_directories('windows_data7');

    filename = [UserInfo.Directories.address , UserInfo.Directories.TIF_video];
    info = imfinfo(filename);
    L = length(info);

    obj = setupSystemObjects(); % Create System objects used for reading video, detecting moving objects, and displaying the results.

    tracks = initializeTracks(); % Create an empty array of tracks.
    nextId = 1; % ID of the next track


    % while ~isDone(obj.reader)   % Detect moving objects, and track them across video frames.
    for index = 1:L
        disp(['index',string(index)])
        frame = reading_frame(index, UserInfo.inputMode);
%         [mask, frame_enhanced] = segmentation(frame);
        frame_enhanced = enhancement_filter(frame, "same");
        mask = segmentation(frame_enhanced, Background);

        Results = detecting_objects(mask);        
        bboxes = Results.bboxes;
        centroids = Results.centroids;
        
        predictNewLocationsOfTracks();
        [assignments, unassignedTracks, unassignedDetections] = detectionToTrackAssignment();

        updateAssignedTracks();
        updateUnassignedTracks();
        deleteLostTracks();
        createNewTracks();
        displayTrackingResults();
    end


    function UserInfo = init_directories(OS)
        
        if strcmp(OS,'linux_data7')
            input_Hard_Drive = '\media\artin\HDD1\';
        elseif strcmp(OS,'windows_data7')
            input_Hard_Drive = 'H:\Datasets\';
        end

        UserInfo.Directories.address   = [input_Hard_Drive, 'FLIR Datasets\Dataset\new_Jan2\'];
        UserInfo.Directories.video     = 'Rec-000020 - Copy - test.wmv';
        UserInfo.Directories.TIF_video = 'Rec-000020 - Copy - test.tif';
        UserInfo.inputMode = 'reading_tif_video';

        if contains(OS,'linux')
             UserInfo.Directories.address = strrep(UserInfo.Directories.address,'\','/');
        end

        UserInfo.invisibleForTooLong = 20;
        UserInfo.ageThreshold = 8; 

        % Kalman Filter Parameters
        UserInfo.costOfNonAssignment = 20;
        UserInfo.MotionModel = 'ConstantVelocity';
        UserInfo.InitialEstimateError = [200, 50];
        UserInfo.MotionNoise = [100, 25];
        UserInfo.MeasurementNoise = 100;

        UserInfo.minVisibleCount = 8;
        
        Pore_Size = inputdlg({'Minimum','Maximum'},'Insert Pore Size',[1,40],{'1','15'});
        UserInfo.pore_size_range = [str2double(Pore_Size{1}) , str2double(Pore_Size{2}) ];
    end

    mask = segmentating_sweat_pores(frame);
        
    
    function im = reading_frame(index, mode)
        
        if strcmp(mode , 'read_from_individual_frames')
            name = ['Rec-000020 - Copy - test_',int2str(index),'.tif'];
            Dirr = [Directories.address, name];
            im = imread(Dirr);
        else
            im = imread(filename, index);
        end
        
        im = func_normalize(im,1);
        
        function im = func_normalize(im,type)
            im = single(im);
            mn = min(im(:));
            mx = max(im(:));
            if type == 16
                im = uint16(  (im-mn)*(2^16)/(mx-mn)  );
            elseif type == 8
                im = uint8(  (im-mn)*(2^8)/(mx-mn)  );
            elseif type == 1
                im = (im-mn)/(mx-mn);
            end
        end

    end

%% Create System Objects
% Create System objects used for reading the video frames, detecting
% foreground objects, and displaying results.

    function obj = setupSystemObjects()
        % Initialize Video I/O
        % Create objects for reading a video from a file, drawing the tracked
        % objects in each frame, and playing the video.
        
        % Create a video file reader.
        %         obj.reader = vision.VideoFileReader('atrium.mp4');
        obj.reader = vision.VideoFileReader([UserInfo.Directories.address , UserInfo.Directories.video]); % 'G:\FLIR Datasets\Dataset\new_Jan2\Rec-000020 - Copy - test.wmv');
        
        % Create two video players, one to display the video,
        % and one to display the foreground mask.
        obj.maskPlayer = vision.VideoPlayer('Position', [740, 400, 700, 400]);
        obj.videoPlayer = vision.VideoPlayer('Position', [20, 400, 700, 400]);
        
        % Create System objects for foreground detection and blob analysis
        
        % The foreground detector is used to segment moving objects from
        % the background. It outputs a binary mask, where the pixel value
        % of 1 corresponds to the foreground and the value of 0 corresponds
        % to the background.
        
        obj.detector = vision.ForegroundDetector('NumGaussians', 3, ...
            'NumTrainingFrames', 40, 'MinimumBackgroundRatio', 0.7);
        
        % Connected groups of foreground pixels are likely to correspond to moving
        % objects.  The blob analysis System object is used to find such groups
        % (called 'blobs' or 'connected components'), and compute their
        % characteristics, such as area, centroid, and the bounding box.
        
        obj.blobAnalyser = vision.BlobAnalysis('BoundingBoxOutputPort', true, ...
            'AreaOutputPort', true, 'CentroidOutputPort', true, ...
            'MinimumBlobArea', 400);
    end

%% Initialize Tracks
% The |initializeTracks| function creates an array of tracks, where each
% track is a structure representing a moving object in the video. The
% purpose of the structure is to maintain the state of a tracked object.
% The state consists of information used for detection to track assignment,
% track termination, and display.
%
% The structure contains the following fields:
%
% * |id| :                  the integer ID of the track
% * |bbox| :                the current bounding box of the object; used
%                           for display
% * |kalmanFilter| :        a Kalman filter object used for motion-based
%                           tracking
% * |age| :                 the number of frames since the track was first
%                           detected
% * |totalVisibleCount| :   the total number of frames in which the track
%                           was detected (visible)
% * |consecutiveInvisibleCount| : the number of consecutive frames for
%                                  which the track was not detected (invisible).
%
% Noisy detections tend to result in short-lived tracks. For this reason,
% the example only displays an object after it was tracked for some number
% of frames. This happens when |totalVisibleCount| exceeds a specified
% threshold.
%
% When no detections are associated with a track for several consecutive
% frames, the example assumes that the object has left the field of view
% and deletes the track. This happens when |consecutiveInvisibleCount|
% exceeds a specified threshold. A track may also get deleted as noise if
% it was tracked for a short time, and marked invisible for most of the
% frames.

    function tracks = initializeTracks()
        % create an empty array of tracks
        tracks = struct(...
            'id', {}, ...
            'bbox', {}, ...
            'kalmanFilter', {}, ...
            'age', {}, ...
            'totalVisibleCount', {}, ...
            'consecutiveInvisibleCount', {});
    end

%% Read a Video Frame
% Read the next video frame from the video file.
    function frame = readFrame()
        frame = obj.reader.step();
    end


%% Predict New Locations of Existing Tracks
% Use the Kalman filter to predict the centroid of each track in the
% current frame, and update its bounding box accordingly.

    function predictNewLocationsOfTracks()
        for i = 1:length(tracks)
            bbox = tracks(i).bbox;
            
            % Predict the current location of the track.
            predictedCentroid = predict(tracks(i).kalmanFilter);
            
            % Shift the bounding box so that its center is at
            % the predicted location.
            predictedCentroid = int32(predictedCentroid) - bbox(3:4) / 2;
            tracks(i).bbox = [predictedCentroid, bbox(3:4)];
        end
    end

%% Assign Detections to Tracks
% Assigning object detections in the current frame to existing tracks is
% done by minimizing cost. The cost is defined as the negative
% log-likelihood of a detection corresponding to a track.
%
% The algorithm involves two steps:
%
% Step 1: Compute the cost of assigning every detection to each track using
% the |distance| method of the |vision.KalmanFilter| System object(TM). The
% cost takes into account the Euclidean distance between the predicted
% centroid of the track and the centroid of the detection. It also includes
% the confidence of the prediction, which is maintained by the Kalman
% filter. The results are stored in an MxN matrix, where M is the number of
% tracks, and N is the number of detections.
%
% Step 2: Solve the assignment problem represented by the cost matrix using
% the |assignDetectionsToTracks| function. The function takes the cost
% matrix and the cost of not assigning any detections to a track.
%
% The value for the cost of not assigning a detection to a track depends on
% the range of values returned by the |distance| method of the
% |vision.KalmanFilter|. This value must be tuned experimentally. Setting
% it too low increases the likelihood of creating a new track, and may
% result in track fragmentation. Setting it too high may result in a single
% track corresponding to a series of separate moving objects.
%
% The |assignDetectionsToTracks| function uses the Munkres' version of the
% Hungarian algorithm to compute an assignment which minimizes the total
% cost. It returns an M x 2 matrix containing the corresponding indices of
% assigned tracks and detections in its two columns. It also returns the
% indices of tracks and detections that remained unassigned.

    function [assignments, unassignedTracks, unassignedDetections] = detectionToTrackAssignment()
        
        nTracks = length(tracks);
        nDetections = size(centroids, 1);
        
        % Compute the cost of assigning each detection to each track.
        cost = zeros(nTracks, nDetections);
        for i = 1:nTracks
            cost(i, :) = distance(tracks(i).kalmanFilter, centroids);
        end
        
        % Solve the assignment problem.
        costOfNonAssignment = UserInfo.costOfNonAssignment; %  20;
        [assignments, unassignedTracks, unassignedDetections] = ...
            assignDetectionsToTracks(cost, costOfNonAssignment);
    end

%% Update Assigned Tracks
% The |updateAssignedTracks| function updates each assigned track with the
% corresponding detection. It calls the |correct| method of
% |vision.KalmanFilter| to correct the location estimate. Next, it stores
% the new bounding box, and increases the age of the track and the total
% visible count by 1. Finally, the function sets the invisible count to 0.

    function updateAssignedTracks()
        numAssignedTracks = size(assignments, 1);
        for i = 1:numAssignedTracks
            trackIdx = assignments(i, 1);
            detectionIdx = assignments(i, 2);
            centroid = centroids(detectionIdx, :);
            bbox = bboxes(detectionIdx, :);
            
            % Correct the estimate of the object's location
            % using the new detection.
            correct(tracks(trackIdx).kalmanFilter, centroid);
            
            % Replace predicted bounding box with detected
            % bounding box.
            tracks(trackIdx).bbox = bbox;
            
            % Update track's age.
            tracks(trackIdx).age = tracks(trackIdx).age + 1;
            
            % Update visibility.
            tracks(trackIdx).totalVisibleCount = ...
                tracks(trackIdx).totalVisibleCount + 1;
            tracks(trackIdx).consecutiveInvisibleCount = 0;
        end
    end

%% Update Unassigned Tracks
% Mark each unassigned track as invisible, and increase its age by 1.

    function updateUnassignedTracks()
        for i = 1:length(unassignedTracks)
            ind = unassignedTracks(i);
            tracks(ind).age = tracks(ind).age + 1;
            tracks(ind).consecutiveInvisibleCount = ...
                tracks(ind).consecutiveInvisibleCount + 1;
        end
    end

%% Delete Lost Tracks
% The |deleteLostTracks| function deletes tracks that have been invisible
% for too many consecutive frames. It also deletes recently created tracks
% that have been invisible for too many frames overall.

    function deleteLostTracks()
        if isempty(tracks)
            return;
        end
        
        invisibleForTooLong = UserInfo.invisibleForTooLong; % 20;
        ageThreshold = UserInfo.ageThreshold; %  8;
        
        % Compute the fraction of the track's age for which it was visible.
        ages = [tracks(:).age];
        totalVisibleCounts = [tracks(:).totalVisibleCount];
        visibility = totalVisibleCounts ./ ages;
        
        % Find the indices of 'lost' tracks.
        lostInds = (ages < ageThreshold & visibility < 0.6) | ...
            [tracks(:).consecutiveInvisibleCount] >= invisibleForTooLong;
        
        % Delete lost tracks.
        tracks = tracks(~lostInds);
    end

%% Create New Tracks
% Create new tracks from unassigned detections. Assume that any unassigned
% detection is a start of a new track. In practice, you can use other cues
% to eliminate noisy detections, such as size, location, or appearance.

    function createNewTracks()
        centroids = centroids(unassignedDetections, :);
        bboxes = bboxes(unassignedDetections, :);
        
        for i = 1:size(centroids, 1)
            
            centroid = centroids(i,:);
            bbox = bboxes(i, :);
            
            % Create a Kalman filter object.
            kalmanFilter = configureKalmanFilter(UserInfo.MotionModel, centroid, UserInfo.InitialEstimateError, UserInfo.MotionNoise, UserInfo.MeasurementNoise);
                
            
            % Create a new track.
            newTrack = struct(...
                'id', nextId, ...
                'bbox', bbox, ...
                'kalmanFilter', kalmanFilter, ...
                'age', 1, ...
                'totalVisibleCount', 1, ...
                'consecutiveInvisibleCount', 0);
            
            % Add it to the array of tracks.
            tracks(end + 1) = newTrack;
            
            % Increment the next id.
            nextId = nextId + 1;
        end
    end

%% Display Tracking Results
% The |displayTrackingResults| function draws a bounding box and label ID
% for each track on the video frame and the foreground mask. It then
% displays the frame and the mask in their respective video players.

    function displayTrackingResults()
        % Convert the frame and the mask to uint8 RGB.
        frame = uint8(repmat(frame, [1, 1, 3]) .* 255); %im2uint8(frame);
        mask = uint8(repmat(mask, [1, 1, 3])) .* 255;
        
        minVisibleCount = UserInfo.minVisibleCount; %8;
        if ~isempty(tracks)
            
            % Noisy detections tend to result in short-lived tracks.
            % Only display tracks that have been visible for more than
            % a minimum number of frames.
            reliableTrackInds = [tracks(:).totalVisibleCount] > minVisibleCount;
            reliableTracks = tracks(reliableTrackInds);
            
            % Display the objects. If an object has not been detected
            % in this frame, display its predicted bounding box.
            if ~isempty(reliableTracks)
                % Get bounding boxes.
                pore_ID = cat(1,tracks.id);
                Time_Pore_Stayed_Active = cat(1,tracks.totalVisibleCount);
                When_Pore_Appeared = cat(1,tracks.age);
                T = table(pore_ID, Time_Pore_Stayed_Active, When_Pore_Appeared);
                bboxes = cat(1, reliableTracks.bbox);
                
                % Get ids.
                ids = int32([reliableTracks(:).id]);
                
                % Create labels for objects indicating the ones for
                % which we display the predicted rather than the actual
                % location.
                labels = cellstr(int2str(ids'));
                predictedTrackInds = ...
                    [reliableTracks(:).consecutiveInvisibleCount] > 0;
                isPredicted = cell(size(labels));
                isPredicted(predictedTrackInds) = {' predicted'};
                labels = strcat(labels, isPredicted);
                
                % Draw the objects on the frame.
                frame = insertObjectAnnotation(frame, 'rectangle', ...
                    bboxes, labels);
                
                % Draw the objects on the mask.
%                 mask = insertObjectAnnotation(mask, 'rectangle', ...
%                     bboxes, labels);
            end
        end
        
        % Display the mask and the frame.
        obj.maskPlayer.step(mask);
        obj.videoPlayer.step(frame);
    end

%% Summary
% This example created a motion-based system for detecting and
% tracking multiple moving objects. Try using a different video to see if
% you are able to detect and track objects. Try modifying the parameters
% for the detection, assignment, and deletion steps.
%
% The tracking in this example was solely based on motion with the
% assumption that all objects move in a straight line with constant speed.
% When the motion of an object significantly deviates from this model, the
% example may produce tracking errors. Notice the mistake in tracking the
% person labeled #12, when he is occluded by the tree.
%
% The likelihood of tracking errors can be reduced by using a more complex
% motion model, such as constant acceleration, or by using multiple Kalman
% filters for every object. Also, you can incorporate other cues for
% associating detections over time, such as size, shape, and color.


end

##### SOURCE END #####
--></body></html>